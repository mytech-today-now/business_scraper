<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Console Error Filtering for DuckDuckGo Scraping - Business Scraper Documentation</title>
    <link rel="stylesheet" href="style.css" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css"
    />
  </head>
  <body>
    <div class="content-wrapper">
      <div class="back-to-docs">
        <a href="readme.html" class="btn btn-outline-primary"> ‚Üê Back to Documentation Hub </a>
      </div>

      <div class="nav-breadcrumb">
        <nav aria-label="breadcrumb">
          <ol class="breadcrumb mb-0">
            <li class="breadcrumb-item">
              <a href="readme.html">Documentation</a>
            </li>
            <li class="breadcrumb-item active" aria-current="page">
              Console Error Filtering for DuckDuckGo Scraping
            </li>
          </ol>
        </nav>
      </div>

      <main class="documentation-content">
        <h1>Console Error Filtering for DuckDuckGo Scraping</h1>
        <h2>Problem</h2>
        <p>
          When scraping DuckDuckGo search results, the browser console was filled with non-critical
          errors and warnings that made debugging difficult and created noise in logs:
        </p>
        <pre><code>Error with Permissions-Policy header: Unrecognized feature: &#39;interest-cohort&#39;.
useTranslation: DISMISS is not available
Failed to load resource: net::ERR_FAILED
The resource was preloaded using link preload but not used within a few seconds
Failed to load resource: the server responded with a status of 404 ()
</code></pre>
        <h2>Solution</h2>
        <p>Implemented a comprehensive console filtering and resource blocking system that:</p>
        <ol>
          <li>
            <strong>Filters Console Messages</strong>: Automatically filters out non-critical
            browser warnings and errors
          </li>
          <li>
            <strong>Blocks Problematic Resources</strong>: Prevents loading of resources that cause
            console errors
          </li>
          <li>
            <strong>Maintains Critical Error Logging</strong>: Still logs genuine application errors
          </li>
          <li>
            <strong>Improves Performance</strong>: Reduces network requests and browser overhead
          </li>
        </ol>
        <h2>Implementation</h2>
        <h3>1. Console Filter Utilities (<code>src/lib/consoleFilterUtils.ts</code>)</h3>
        <p>Created a reusable utility that provides:</p>
        <ul>
          <li>
            <strong>Predefined Filter Patterns</strong>: Common console noise patterns for different
            scenarios
          </li>
          <li>
            <strong>Configurable Filter Levels</strong>: <code>strict</code>, <code>moderate</code>,
            <code>minimal</code> filtering options
          </li>
          <li><strong>Resource Blocking</strong>: Intelligent blocking of problematic resources</li>
          <li><strong>Clean Scraping Setup</strong>: One-line setup for noise-free scraping</li>
        </ul>
        <h3>2. Enhanced DuckDuckGo Scraper (<code>src/lib/enhancedDuckDuckGoScraper.ts</code>)</h3>
        <p>A specialized scraper with:</p>
        <ul>
          <li>
            <strong>Built-in Console Filtering</strong>: Automatically filters DuckDuckGo-specific
            noise
          </li>
          <li>
            <strong>Enhanced Resource Blocking</strong>: Blocks resources that cause console errors
          </li>
          <li><strong>Retry Logic</strong>: Robust error handling with retry mechanisms</li>
          <li>
            <strong>Performance Optimization</strong>: Faster scraping with reduced resource loading
          </li>
        </ul>
        <h3>3. Updated API Route (<code>src/app/api/search/route.ts</code>)</h3>
        <p>Enhanced the existing DuckDuckGo API route with:</p>
        <ul>
          <li><strong>Integrated Console Filtering</strong>: Uses the new filtering utilities</li>
          <li>
            <strong>Reduced Console Noise</strong>: Filters out the specific errors you were seeing
          </li>
          <li><strong>Maintained Functionality</strong>: All existing features preserved</li>
        </ul>
        <h2>Usage</h2>
        <h3>Basic Console Filtering</h3>
        <pre><code class="language-typescript">import { setupCleanScraping } from &#39;@/lib/consoleFilterUtils&#39;

// Apply to any Puppeteer page
await setupCleanScraping(page, {
  consoleFilter: {
    filterLevel: &#39;moderate&#39;,
    logCriticalErrors: true,
    logPageErrors: true
  },
  resourceBlocking: &#39;moderate&#39;
})
</code></pre>
        <h3>Custom Filtering</h3>
        <pre><code class="language-typescript">import { applyConsoleFiltering } from &#39;@/lib/consoleFilterUtils&#39;

await applyConsoleFiltering(page, {
  filterLevel: &#39;strict&#39;,
  logCriticalErrors: true,
  logPageErrors: true,
  customFilters: [
    &#39;your-specific-error-pattern&#39;,
    &#39;another-pattern-to-filter&#39;
  ]
})
</code></pre>
        <h3>Enhanced DuckDuckGo Scraper</h3>
        <pre><code class="language-typescript">import { EnhancedDuckDuckGoScraper } from &#39;@/lib/enhancedDuckDuckGoScraper&#39;

const scraper = new EnhancedDuckDuckGoScraper()
await scraper.initialize()

const results = await scraper.scrapeResults({
  query: &#39;charter schools near me&#39;,
  page: 0,
  maxResults: 10,
  blockResources: true,
  filterConsole: true
})
</code></pre>
        <h2>Filter Levels</h2>
        <h3>Strict</h3>
        <ul>
          <li>Filters almost all console noise</li>
          <li>Blocks most non-essential resources</li>
          <li>Best for production scraping</li>
        </ul>
        <h3>Moderate (Recommended)</h3>
        <ul>
          <li>Filters common noise patterns</li>
          <li>Allows some warnings through</li>
          <li>Good balance of filtering and visibility</li>
        </ul>
        <h3>Minimal</h3>
        <ul>
          <li>Only filters obvious noise</li>
          <li>Preserves most console output</li>
          <li>Good for debugging</li>
        </ul>
        <h2>Filtered Patterns</h2>
        <h3>DuckDuckGo Specific</h3>
        <ul>
          <li><code>useTranslation: DISMISS is not available</code></li>
          <li><code>expanded-maps-vertical</code> resource errors</li>
          <li><code>duckassist-ia</code> resource errors</li>
          <li><code>wpm.</code> JavaScript/CSS loading errors</li>
        </ul>
        <h3>Browser Policy Warnings</h3>
        <ul>
          <li><code>Permissions-Policy header: Unrecognized feature</code></li>
          <li><code>interest-cohort</code> warnings</li>
          <li><code>browsing-topics</code> warnings</li>
        </ul>
        <h3>Resource Loading Errors</h3>
        <ul>
          <li><code>Failed to load resource</code></li>
          <li><code>net::ERR_FAILED</code></li>
          <li><code>favicon</code> and <code>.ico</code> errors</li>
          <li><code>mapkit</code> and <code>apple-mapkit</code> errors</li>
        </ul>
        <h3>Preload Warnings</h3>
        <ul>
          <li><code>was preloaded using link preload but not used</code></li>
          <li>Link preload timing warnings</li>
        </ul>
        <h2>Benefits</h2>
        <ol>
          <li><strong>Cleaner Logs</strong>: Console output is now focused on actual issues</li>
          <li><strong>Better Performance</strong>: Fewer resources loaded means faster scraping</li>
          <li><strong>Easier Debugging</strong>: Real errors are no longer hidden in noise</li>
          <li><strong>Reusable</strong>: Can be applied to other scraping scenarios</li>
          <li><strong>Configurable</strong>: Different filter levels for different needs</li>
        </ol>
        <h2>Testing</h2>
        <p>Run the console filter tests:</p>
        <pre><code class="language-bash">npm test src/__tests__/lib/consoleFilterUtils.test.ts
</code></pre>
        <h2>Future Enhancements</h2>
        <ul>
          <li>Add more site-specific filter patterns</li>
          <li>Implement machine learning-based noise detection</li>
          <li>Add metrics for filtered vs. critical messages</li>
          <li>Create browser extension for manual testing</li>
        </ul>
        <h2>Notes</h2>
        <ul>
          <li>
            The filtering is conservative - it errs on the side of showing errors rather than hiding
            them
          </li>
          <li>Critical application errors are never filtered</li>
          <li>
            The system can be disabled by setting filter level to <code>minimal</code> or removing
            the setup call
          </li>
          <li>
            All filtered messages are still available in browser dev tools if needed for debugging
          </li>
        </ul>
      </main>

      <footer class="text-center mt-5 pt-4 border-top">
        <p class="text-muted">
          <strong>Business Scraper Application v3.0.0</strong> - Enterprise Multi-User Collaboration
          Platform
        </p>
        <p class="text-muted">
          <a href="readme.html">Documentation Hub</a> |
          <a href="https://github.com/mytech-today-now/business_scraper">GitHub Repository</a>
        </p>
        <p class="text-muted small">Last updated: 8/24/2025</p>
      </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
  </body>
</html>
