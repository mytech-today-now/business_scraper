# Prometheus configuration for Business Scraper monitoring
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: "business-scraper"

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "alert_rules.yml"
  - "recording_rules.yml"

# Scrape configuration
scrape_configs:
  # Business Scraper Application
  - job_name: "business-scraper"
    static_configs:
      - targets: ["localhost:3000"]
    metrics_path: "/api/metrics"
    scrape_interval: 30s
    scrape_timeout: 10s
    honor_labels: true
    params:
      format: ["prometheus"]

  # Node Exporter (system metrics)
  - job_name: "node-exporter"
    static_configs:
      - targets: ["localhost:9100"]
    scrape_interval: 30s

  # PostgreSQL Exporter
  - job_name: "postgres-exporter"
    static_configs:
      - targets: ["localhost:9187"]
    scrape_interval: 30s

  # Redis Exporter
  - job_name: "redis-exporter"
    static_configs:
      - targets: ["localhost:9121"]
    scrape_interval: 30s

  # Prometheus itself
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
    scrape_interval: 30s

  # Grafana
  - job_name: "grafana"
    static_configs:
      - targets: ["localhost:3001"]
    scrape_interval: 60s

# Remote write configuration (optional - for long-term storage)
# remote_write:
#   - url: "http://localhost:8086/api/v1/prom/write?db=prometheus"
#     queue_config:
#       max_samples_per_send: 1000
#       max_shards: 200
#       capacity: 2500

# Storage configuration
storage:
  tsdb:
    retention.time: 30d
    retention.size: 10GB
    path: /prometheus/data

# Web configuration
web:
  console.templates: /etc/prometheus/consoles
  console.libraries: /etc/prometheus/console_libraries
  enable-lifecycle: true
  enable-admin-api: true
